#!/usr/bin/env python3
"""
Spotify Songs' Genre Segmentation AI Model
Project 2: Music Recommendation System

This script implements a comprehensive AI model for genre segmentation and 
music recommendation based on Spotify's audio features and playlist data.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.cluster import KMeans, DBSCAN
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score, calinski_harabasz_score
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics.pairwise import cosine_similarity
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# Set plotting style
plt.style.use('default')
sns.set_palette("husl")

class SpotifyGenreSegmentation:
    """
    A comprehensive class for Spotify genre segmentation and music recommendation
    """
    
    def __init__(self, dataset_path):
        """
        Initialize the SpotifyGenreSegmentation class
        
        Args:
            dataset_path (str): Path to the Spotify dataset CSV file
        """
        self.dataset_path = dataset_path
        self.df = None
        self.df_processed = None
        self.scaler = StandardScaler()
        self.kmeans_model = None
        self.audio_features = None
        self.recommendation_model = None
        
    def load_and_explore_data(self):
        """
        Load the dataset and perform initial exploration
        """
        print("="*60)
        print("SPOTIFY GENRE SEGMENTATION - DATA LOADING & EXPLORATION")
        print("="*60)
        
        # Load dataset
        self.df = pd.read_csv(self.dataset_path)
        print(f"âœ“ Dataset loaded successfully!")
        print(f"Dataset shape: {self.df.shape}")
        print(f"Columns: {len(self.df.columns)}")
        
        # Display basic information
        print("\n" + "="*50)
        print("DATASET OVERVIEW")
        print("="*50)
        print(self.df.info())
        
        print("\n" + "="*50)
        print("FIRST 5 ROWS")
        print("="*50)
        print(self.df.head())
        
        print("\n" + "="*50)
        print("STATISTICAL SUMMARY")
        print("="*50)
        print(self.df.describe())
        
        # Check for missing values
        print("\n" + "="*50)
        print("MISSING VALUES")
        print("="*50)
        missing_values = self.df.isnull().sum()
        missing_percent = (missing_values / len(self.df)) * 100
        missing_df = pd.DataFrame({
            'Missing Count': missing_values,
            'Missing Percentage': missing_percent
        })
        print(missing_df[missing_df['Missing Count'] > 0])
        
        # Unique values for categorical columns
        print("\n" + "="*50)
        print("UNIQUE VALUES IN CATEGORICAL COLUMNS")
        print("="*50)
        categorical_columns = self.df.select_dtypes(include=['object']).columns
        for col in categorical_columns:
            print(f"{col}: {self.df[col].nunique()} unique values")
            if self.df[col].nunique() < 20:
                print(f"Values: {self.df[col].unique()[:10]}")
            print("-" * 30)
    
    def data_preprocessing(self):
        """
        Perform comprehensive data preprocessing
        """
        print("\n" + "="*60)
        print("DATA PREPROCESSING")
        print("="*60)
        
        # Create a copy for processing
        self.df_processed = self.df.copy()
        
        # Handle missing values
        print("âœ“ Handling missing values...")
        # Fill missing numerical values with median
        numerical_columns = self.df_processed.select_dtypes(include=[np.number]).columns
        for col in numerical_columns:
            if self.df_processed[col].isnull().sum() > 0:
                self.df_processed[col].fillna(self.df_processed[col].median(), inplace=True)
        
        # Fill missing categorical values with mode
        categorical_columns = self.df_processed.select_dtypes(include=['object']).columns
        for col in categorical_columns:
            if self.df_processed[col].isnull().sum() > 0:
                self.df_processed[col].fillna(self.df_processed[col].mode()[0], inplace=True)
        
        # Remove duplicates
        print("âœ“ Removing duplicates...")
        initial_shape = self.df_processed.shape
        self.df_processed = self.df_processed.drop_duplicates()
        print(f"Removed {initial_shape[0] - self.df_processed.shape[0]} duplicate rows")
        
        # Identify audio features (typically numerical features related to song characteristics)
        potential_audio_features = []
        for col in numerical_columns:
            # Common Spotify audio features
            if any(feature in col.lower() for feature in [
                'danceability', 'energy', 'speechiness', 'acousticness',
                'instrumentalness', 'liveness', 'valence', 'tempo',
                'loudness', 'duration', 'popularity'
            ]):
                potential_audio_features.append(col)
        
        # If we can't find specific audio features, use numerical columns
        if not potential_audio_features:
            potential_audio_features = [col for col in numerical_columns if col not in ['year', 'release_date']]
        
        self.audio_features = potential_audio_features
        print(f"âœ“ Identified audio features: {self.audio_features}")
        
        # Handle outliers using IQR method
        print("âœ“ Handling outliers...")
        for feature in self.audio_features:
            if feature in self.df_processed.columns:
                Q1 = self.df_processed[feature].quantile(0.25)
                Q3 = self.df_processed[feature].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                
                # Cap outliers instead of removing them to preserve data
                self.df_processed[feature] = np.clip(self.df_processed[feature], lower_bound, upper_bound)
        
        print(f"âœ“ Preprocessing completed! Final dataset shape: {self.df_processed.shape}")
    
    def create_comprehensive_visualizations(self):
        """
        Create all possible plots for data analysis and insights
        """
        print("\n" + "="*60)
        print("COMPREHENSIVE DATA ANALYSIS & VISUALIZATIONS")
        print("="*60)
        
        # Set up the plotting environment
        plt.rcParams['figure.figsize'] = (15, 10)
        
        # 1. Distribution plots for audio features
        print("âœ“ Creating distribution plots...")
        if len(self.audio_features) >= 4:
            fig, axes = plt.subplots(2, 2, figsize=(20, 15))
            axes = axes.ravel()
            
            for i, feature in enumerate(self.audio_features[:4]):
                if feature in self.df_processed.columns:
                    # Histogram with KDE
                    axes[i].hist(self.df_processed[feature], bins=50, alpha=0.7, color='skyblue', edgecolor='black')
                    axes[i].set_title(f'Distribution of {feature}', fontsize=14, fontweight='bold')
                    axes[i].set_xlabel(feature)
                    axes[i].set_ylabel('Frequency')
                    axes[i].grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig('distribution_plots.png', dpi=300, bbox_inches='tight')
            plt.show()
        
        # 2. Box plots for outlier detection
        print("âœ“ Creating box plots...")
        if len(self.audio_features) >= 4:
            fig, axes = plt.subplots(2, 2, figsize=(20, 15))
            axes = axes.ravel()
            
            for i, feature in enumerate(self.audio_features[:4]):
                if feature in self.df_processed.columns:
                    sns.boxplot(data=self.df_processed, y=feature, ax=axes[i])
                    axes[i].set_title(f'Box Plot of {feature}', fontsize=14, fontweight='bold')
                    axes[i].grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig('box_plots.png', dpi=300, bbox_inches='tight')
            plt.show()
        
        # 3. Scatter plots for feature relationships
        print("âœ“ Creating scatter plots...")
        if len(self.audio_features) >= 2:
            fig, axes = plt.subplots(2, 2, figsize=(20, 15))
            axes = axes.ravel()
            
            feature_pairs = [(0, 1), (0, 2), (1, 2), (0, 3)] if len(self.audio_features) >= 4 else [(0, 1)]
            
            for i, (idx1, idx2) in enumerate(feature_pairs[:4]):
                if idx1 < len(self.audio_features) and idx2 < len(self.audio_features):
                    feature1, feature2 = self.audio_features[idx1], self.audio_features[idx2]
                    if feature1 in self.df_processed.columns and feature2 in self.df_processed.columns:
                        axes[i].scatter(self.df_processed[feature1], self.df_processed[feature2], 
                                      alpha=0.6, s=30, color='coral')
                        axes[i].set_xlabel(feature1)
                        axes[i].set_ylabel(feature2)
                        axes[i].set_title(f'{feature1} vs {feature2}', fontsize=14, fontweight='bold')
                        axes[i].grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig('scatter_plots.png', dpi=300, bbox_inches='tight')
            plt.show()
        
        # 4. Genre/Playlist distribution (if available)
        categorical_columns = self.df_processed.select_dtypes(include=['object']).columns
        if len(categorical_columns) > 0:
            print("âœ“ Creating categorical distribution plots...")
            
            # Find genre-like or playlist-like columns
            genre_cols = [col for col in categorical_columns if 
                         any(keyword in col.lower() for keyword in ['genre', 'playlist', 'category', 'type'])]
            
            if genre_cols:
                plt.figure(figsize=(15, 8))
                col_to_plot = genre_cols[0]
                value_counts = self.df_processed[col_to_plot].value_counts().head(15)
                
                plt.bar(range(len(value_counts)), value_counts.values, color='lightgreen', edgecolor='black')
                plt.title(f'Distribution of {col_to_plot}', fontsize=16, fontweight='bold')
                plt.xlabel(col_to_plot)
                plt.ylabel('Count')
                plt.xticks(range(len(value_counts)), value_counts.index, rotation=45, ha='right')
                plt.grid(True, alpha=0.3)
                plt.tight_layout()
                plt.savefig('genre_distribution.png', dpi=300, bbox_inches='tight')
                plt.show()
        
        print("âœ“ All visualizations created successfully!")
    
    def create_correlation_matrix(self):
        """
        Create and display correlation matrix of features
        """
        print("\n" + "="*60)
        print("CORRELATION MATRIX ANALYSIS")
        print("="*60)
        
        # Select numerical features for correlation
        numerical_features = [col for col in self.audio_features if col in self.df_processed.columns]
        
        if len(numerical_features) >= 2:
            # Calculate correlation matrix
            correlation_matrix = self.df_processed[numerical_features].corr()
            
            # Create heatmap
            plt.figure(figsize=(12, 10))
            mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
            
            sns.heatmap(correlation_matrix, 
                       mask=mask,
                       annot=True, 
                       cmap='RdYlBu_r', 
                       center=0,
                       square=True, 
                       linewidths=0.5, 
                       cbar_kws={"shrink": .8},
                       fmt='.2f')
            
            plt.title('Feature Correlation Matrix', fontsize=16, fontweight='bold', pad=20)
            plt.tight_layout()
            plt.savefig('correlation_matrix.png', dpi=300, bbox_inches='tight')
            plt.show()
            
            # Print highly correlated features
            print("\nHighly Correlated Features (|correlation| > 0.7):")
            high_corr_pairs = []
            for i in range(len(correlation_matrix.columns)):
                for j in range(i+1, len(correlation_matrix.columns)):
                    corr_val = correlation_matrix.iloc[i, j]
                    if abs(corr_val) > 0.7:
                        high_corr_pairs.append((correlation_matrix.columns[i], 
                                              correlation_matrix.columns[j], 
                                              corr_val))
            
            if high_corr_pairs:
                for feature1, feature2, corr in high_corr_pairs:
                    print(f"{feature1} â†” {feature2}: {corr:.3f}")
            else:
                print("No highly correlated feature pairs found.")
        
        else:
            print("Not enough numerical features for correlation analysis.")
    
    def perform_clustering_analysis(self):
        """
        Perform clustering analysis with different parameters
        """
        print("\n" + "="*60)
        print("CLUSTERING ANALYSIS")
        print("="*60)
        
        # Prepare features for clustering
        clustering_features = [col for col in self.audio_features if col in self.df_processed.columns]
        
        if len(clustering_features) < 2:
            print("Not enough features for clustering analysis.")
            return
        
        X = self.df_processed[clustering_features].copy()
        
        # Standardize features
        X_scaled = self.scaler.fit_transform(X)
        
        # 1. Determine optimal number of clusters using Elbow Method
        print("âœ“ Finding optimal number of clusters...")
        
        inertias = []
        silhouette_scores = []
        K_range = range(2, 11)
        
        for k in K_range:
            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
            kmeans.fit(X_scaled)
            inertias.append(kmeans.inertia_)
            silhouette_scores.append(silhouette_score(X_scaled, kmeans.labels_))
        
        # Plot elbow curve and silhouette scores
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # Elbow curve
        ax1.plot(K_range, inertias, 'bo-')
        ax1.set_xlabel('Number of Clusters (k)')
        ax1.set_ylabel('Inertia')
        ax1.set_title('Elbow Method for Optimal k')
        ax1.grid(True, alpha=0.3)
        
        # Silhouette scores
        ax2.plot(K_range, silhouette_scores, 'ro-')
        ax2.set_xlabel('Number of Clusters (k)')
        ax2.set_ylabel('Silhouette Score')
        ax2.set_title('Silhouette Score vs Number of Clusters')
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('clustering_optimization.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # Find optimal k (highest silhouette score)
        optimal_k = K_range[np.argmax(silhouette_scores)]
        print(f"âœ“ Optimal number of clusters: {optimal_k} (Silhouette Score: {max(silhouette_scores):.3f})")
        
        # 2. Perform final clustering
        print(f"âœ“ Performing K-Means clustering with k={optimal_k}...")
        self.kmeans_model = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
        cluster_labels = self.kmeans_model.fit_predict(X_scaled)
        
        # Add cluster labels to dataframe
        self.df_processed['cluster'] = cluster_labels
        
        # 3. Analyze clusters
        print("\nCluster Analysis:")
        print("=" * 40)
        
        for i in range(optimal_k):
            cluster_data = self.df_processed[self.df_processed['cluster'] == i]
            print(f"\nCluster {i} ({len(cluster_data)} songs):")
            
            # Calculate cluster characteristics
            for feature in clustering_features:
                mean_val = cluster_data[feature].mean()
                print(f"  {feature}: {mean_val:.3f}")
        
        # 4. Visualize clusters using PCA
        print("âœ“ Creating cluster visualizations...")
        
        # PCA for dimensionality reduction
        pca = PCA(n_components=2)
        X_pca = pca.fit_transform(X_scaled)
        
        # Create cluster visualization
        plt.figure(figsize=(12, 8))
        colors = plt.cm.tab10(np.linspace(0, 1, optimal_k))
        
        for i in range(optimal_k):
            mask = cluster_labels == i
            plt.scatter(X_pca[mask, 0], X_pca[mask, 1], 
                       c=[colors[i]], label=f'Cluster {i}', alpha=0.6, s=50)
        
        plt.xlabel(f'First Principal Component ({pca.explained_variance_ratio_[0]:.1%} variance)')
        plt.ylabel(f'Second Principal Component ({pca.explained_variance_ratio_[1]:.1%} variance)')
        plt.title('Song Clusters Visualization (PCA)', fontsize=14, fontweight='bold')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig('cluster_visualization.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # 5. Create cluster comparison plots
        if len(clustering_features) >= 2:
            fig, axes = plt.subplots(2, 2, figsize=(16, 12))
            axes = axes.ravel()
            
            for i, feature in enumerate(clustering_features[:4]):
                if i < 4:
                    for cluster_id in range(optimal_k):
                        cluster_data = self.df_processed[self.df_processed['cluster'] == cluster_id][feature]
                        axes[i].hist(cluster_data, alpha=0.6, label=f'Cluster {cluster_id}', bins=20)
                    
                    axes[i].set_title(f'{feature} Distribution by Cluster')
                    axes[i].set_xlabel(feature)
                    axes[i].set_ylabel('Frequency')
                    axes[i].legend()
                    axes[i].grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig('cluster_feature_distributions.png', dpi=300, bbox_inches='tight')
            plt.show()
    
    def build_recommendation_model(self):
        """
        Build a content-based recommendation system using clustering results
        """
        print("\n" + "="*60)
        print("BUILDING RECOMMENDATION SYSTEM")
        print("="*60)
        
        if self.kmeans_model is None:
            print("Error: Clustering must be performed first!")
            return
        
        # Prepare features for recommendation
        recommendation_features = [col for col in self.audio_features if col in self.df_processed.columns]
        
        if len(recommendation_features) < 2:
            print("Not enough features for building recommendation system.")
            return
        
        # Create feature matrix
        feature_matrix = self.df_processed[recommendation_features].values
        feature_matrix_scaled = self.scaler.transform(feature_matrix)
        
        # Build KNN model for finding similar songs
        self.recommendation_model = NearestNeighbors(
            n_neighbors=10, 
            metric='euclidean',
            algorithm='auto'
        )
        self.recommendation_model.fit(feature_matrix_scaled)
        
        print("âœ“ Recommendation model built successfully!")
        
        # Calculate similarity matrix for evaluation
        similarity_matrix = cosine_similarity(feature_matrix_scaled)
        
        print(f"âœ“ Similarity matrix created: {similarity_matrix.shape}")
        print(f"âœ“ Average similarity score: {np.mean(similarity_matrix):.3f}")
        
    def recommend_songs(self, song_index=None, song_name=None, n_recommendations=5):
        """
        Recommend songs based on similarity
        
        Args:
            song_index (int): Index of the song in the dataset
            song_name (str): Name of the song (if available)
            n_recommendations (int): Number of recommendations to return
        
        Returns:
            pandas.DataFrame: Recommended songs
        """
        if self.recommendation_model is None:
            print("Error: Recommendation model not built!")
            return None
        
        # Find song index if song name is provided
        if song_name and 'track_name' in self.df_processed.columns:
            matching_songs = self.df_processed[
                self.df_processed['track_name'].str.contains(song_name, case=False, na=False)
            ]
            if not matching_songs.empty:
                song_index = matching_songs.index[0]
                print(f"Found song: {matching_songs.iloc[0]['track_name']}")
            else:
                print(f"Song '{song_name}' not found!")
                return None
        
        # Use random song if no index provided
        if song_index is None:
            song_index = np.random.randint(0, len(self.df_processed))
        
        # Get song features
        recommendation_features = [col for col in self.audio_features if col in self.df_processed.columns]
        song_features = self.df_processed.iloc[song_index][recommendation_features].values.reshape(1, -1)
        song_features_scaled = self.scaler.transform(song_features)
        
        # Find similar songs
        distances, indices = self.recommendation_model.kneighbors(song_features_scaled, n_neighbors=n_recommendations+1)
        
        # Get recommendations (excluding the input song itself)
        recommended_indices = indices[0][1:]  # Skip the first one (input song itself)
        
        # Create recommendation dataframe
        recommendations = self.df_processed.iloc[recommended_indices].copy()
        recommendations['similarity_score'] = 1 - distances[0][1:]  # Convert distance to similarity
        
        # Display original song info
        original_song = self.df_processed.iloc[song_index]
        print(f"\nðŸŽµ ORIGINAL SONG:")
        print(f"Index: {song_index}")
        if 'track_name' in original_song:
            print(f"Name: {original_song['track_name']}")
        if 'artist_name' in original_song:
            print(f"Artist: {original_song['artist_name']}")
        print(f"Cluster: {original_song['cluster']}")
        
        print(f"\nðŸŽ¯ TOP {n_recommendations} RECOMMENDATIONS:")
        print("=" * 70)
        
        for i, (idx, row) in enumerate(recommendations.iterrows()):
            print(f"\n{i+1}. Similarity Score: {row['similarity_score']:.3f}")
            if 'track_name' in row:
                print(f"   Track: {row['track_name']}")
            if 'artist_name' in row:
                print(f"   Artist: {row['artist_name']}")
            print(f"   Cluster: {row['cluster']}")
            print(f"   Index: {idx}")
        
        return recommendations
    
    def evaluate_model_performance(self):
        """
        Evaluate the performance of the clustering and recommendation model
        """
        print("\n" + "="*60)
        print("MODEL PERFORMANCE EVALUATION")
        print("="*60)
        
        if self.kmeans_model is None:
            print("Error: Model not trained!")
            return
        
        # Prepare features
        clustering_features = [col for col in self.audio_features if col in self.df_processed.columns]
        X = self.df_processed[clustering_features].values
        X_scaled = self.scaler.transform(X)
        
        # Get cluster labels
        cluster_labels = self.df_processed['cluster'].values
        
        # Calculate clustering metrics
        silhouette_avg = silhouette_score(X_scaled, cluster_labels)
        calinski_harabasz = calinski_harabasz_score(X_scaled, cluster_labels)
        inertia = self.kmeans_model.inertia_
        
        print("CLUSTERING PERFORMANCE METRICS:")
        print("=" * 40)
        print(f"Silhouette Score: {silhouette_avg:.4f}")
        print(f"Calinski-Harabasz Index: {calinski_harabasz:.4f}")
        print(f"Inertia (Within-cluster sum of squares): {inertia:.4f}")
        
        # Cluster distribution
        print(f"\nCLUSTER DISTRIBUTION:")
        print("=" * 25)
        cluster_counts = self.df_processed['cluster'].value_counts().sort_index()
        for cluster_id, count in cluster_counts.items():
            percentage = (count / len(self.df_processed)) * 100
            print(f"Cluster {cluster_id}: {count} songs ({percentage:.1f}%)")
        
        # Model interpretation
        print(f"\nðŸ“Š MODEL INTERPRETATION:")
        print("=" * 30)
        if silhouette_avg > 0.5:
            print("âœ“ Excellent clustering structure")
        elif silhouette_avg > 0.3:
            print("âœ“ Good clustering structure")
        elif silhouette_avg > 0.2:
            print("âš  Fair clustering structure")
        else:
            print("âš  Poor clustering structure - consider different parameters")
        
        print(f"\nðŸŽ¯ RECOMMENDATION SYSTEM READY!")
        print("The model can now provide personalized music recommendations based on:")
        print("â€¢ Audio features similarity")
        print("â€¢ Genre clustering")
        print("â€¢ Content-based filtering")
        
    def run_complete_analysis(self):
        """
        Run the complete analysis pipeline
        """
        print("ðŸŽµ" * 20)
        print("SPOTIFY GENRE SEGMENTATION AI MODEL")
        print("ðŸŽµ" * 20)
        
        try:
            # Step 1: Load and explore data
            self.load_and_explore_data()
            
            # Step 2: Data preprocessing
            self.data_preprocessing()
            
            # Step 3: Create visualizations
            self.create_comprehensive_visualizations()
            
            # Step 4: Correlation analysis
            self.create_correlation_matrix()
            
            # Step 5: Clustering analysis
            self.perform_clustering_analysis()
            
            # Step 6: Build recommendation model
            self.build_recommendation_model()
            
            # Step 7: Evaluate model performance
            self.evaluate_model_performance()
            
            print("\n" + "="*60)
            print("ðŸŽ‰ ANALYSIS COMPLETED SUCCESSFULLY!")
            print("="*60)
            print("ðŸ“ Generated files:")
            print("â€¢ distribution_plots.png")
            print("â€¢ box_plots.png")
            print("â€¢ scatter_plots.png")
            print("â€¢ genre_distribution.png")
            print("â€¢ correlation_matrix.png")
            print("â€¢ clustering_optimization.png")
            print("â€¢ cluster_visualization.png")
            print("â€¢ cluster_feature_distributions.png")
            
            return True
            
        except Exception as e:
            print(f"âŒ Error during analysis: {str(e)}")
            import traceback
            traceback.print_exc()
            return False

def main():
    """
    Main function to run the Spotify Genre Segmentation analysis
    """
    # Initialize the model
    spotify_model = SpotifyGenreSegmentation('spotify_dataset.csv')
    
    # Run complete analysis
    success = spotify_model.run_complete_analysis()
    
    if success:
        print("\n" + "="*60)
        print("ðŸŽµ RECOMMENDATION SYSTEM DEMO")
        print("="*60)
        
        # Demo recommendations
        print("\nðŸ” Demonstrating recommendation system...")
        
        # Get recommendations for a random song
        recommendations = spotify_model.recommend_songs(n_recommendations=5)
        
        # Try another recommendation if the dataset has enough songs
        if len(spotify_model.df_processed) > 100:
            print("\n" + "-"*50)
            print("ðŸŽµ Another recommendation example:")
            spotify_model.recommend_songs(song_index=50, n_recommendations=3)

if __name__ == "__main__":
    main()
